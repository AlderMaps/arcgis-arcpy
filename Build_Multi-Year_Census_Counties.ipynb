{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d16f935",
   "metadata": {},
   "source": [
    "# Census County GIS Data Cross-Year Exploration\n",
    "\n",
    "This Python (ArcPy) script arose from the data exploration phase of an ArcGIS script + Dashboard project begun in summer 2025 (at the beginning of my post-[Deferred Resignation Program](https://en.wikipedia.org/wiki/2025_U.S._federal_deferred_resignation_program) professional gap year[ish]).\n",
    "\n",
    "The project centers on an ArcGIS Dashboard that displays FEMA US county Disaster Declarations, and is powered by a script that automatically updates the map on a daily basis. This Dashboard promises to be a near-real-time, interactive version of static PDFs I often made for USDA HSD (Homeland Security Division) personnel with whom I worked while I was with USDA GEO (which is the role I exited via [DRP](https://en.wikipedia.org/wiki/2025_U.S._federal_deferred_resignation_program)).\n",
    "\n",
    "This Dashboard has at its core a simple dataset comprising US county geographies (which are joined to FEMA Disaster Declaration data via FIPS codes). I know from my work with USDAâ€”specifically from my partnership on multiple projects with FSAâ€”that FIPS codes do occasionally change from year to year. (An unusual and somewhat extreme example is the [shake-up of Connecticut counties in 2022](https://www.federalregister.gov/documents/2022/06/06/2022-12063/change-to-county-equivalents-in-the-state-of-connecticut)).\n",
    "\n",
    "If I want to represent FEMA Disaster Declaration data across multiple years, I must ensure that my US county data reflects all FIPS codes from the same span of years. If, for example, I simply used the most recent US Counties dataset from US Census Bureau, any Disaster Declarations from before 2022 for Connecticut (specifically, County FIPS codes from before 2022) would not join to post-2022 counties, and those Declarations would therefore not be reflected in my Dashboard.\n",
    "\n",
    "This Python script therefore represented an interest on my part in discovering just how many FIPS codes have changed within my temporal range of data interest.\n",
    "\n",
    "I also know from my time with USDA that US County geographies are also subject to occasional change. Often these changes are small, e.g. an adjustment along a migrating meandering river. Nevertheless I figure I may as well explore the US county geography changes as long as I am already programmatically mucking about in the guts of US county geodatabases.\n",
    "\n",
    "Additional ulterior motives: I don't really have an updated (Python 3.x) script in my GIS Portfolio which primary purpose is mucking about in the guts of geodatabases: data access cursors and all that. And, finally: Python is just obscenely fun.\n",
    "\n",
    "P.S. This script took two days to put together. The ONLY thing ChatGPT helped with was clueing me into the existence of the \"template\" parameter for the ArcPy .CreateFeatureclass() method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d0a8a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a20aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from zipfile import ZipFile\n",
    "import arcpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a3cc03",
   "metadata": {},
   "source": [
    "### Switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f61109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to toggle between running on US Census Counties or US Census Tribal Areas\n",
    "# (since Disaster Declarations can be for either)\n",
    "\n",
    "# Input \"Counties\" or \"Tribal\":\n",
    "dataset = \"tribal\"\n",
    "\n",
    "# Switch to toggle between comparing based solely on GEOID\n",
    "# or both GEOID and feature geometry:\n",
    "\n",
    "# Input \"geoid\" or \"both\":\n",
    "compare = \"geoid\"\n",
    "\n",
    "# A value (a very small value) representing the number of degrees\n",
    "# that two counties or tribal areas with the same GEOID may differ in SHAPE@LENGTH\n",
    "# above which we will consider their geometries sufficiently different that\n",
    "# both geometries are written to the output feature class.\n",
    "\n",
    "# How much is significant? I ran the input counties through the wringer multiple times\n",
    "# with different values; the smaller the difference, the more counties will be written.\n",
    "# For example, running Census years 2013-2025,\n",
    "# the numbers are as follows:\n",
    "# .01: 3675 counties\n",
    "# .005: 3945 counties | .001: 4897 counties\n",
    "# .0005: 5454 counties | .0001: 6877 counties\n",
    "# .00001: 8646 counties\n",
    "# Obviously the numbers indicate that over the years many, many, tiny changes\n",
    "# and adjustments are made (happen? is it deliberate? magic?) to US Census counties.\n",
    "\n",
    "degrees = .0001 # Value is very SMALL because unit is DEGREES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba994c",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f61d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The base directory in which my zipped Census files, output GDB etc reside.\n",
    "base_dir = r\"C:\\Users\\Misti\\OneDrive\\PROJECTS\\2025_08_Multi-Year_Census_Counties\"\n",
    "\n",
    "# Output geodatabase, to which my Frankenstein multi-year US counties feature class will be written\n",
    "output_gdb = r\"2025_08_Multi-Year_Census_Counties.gdb\"\n",
    "\n",
    "# Set variables based on whether switch is \"Counties\" or \"Tribal\":\n",
    "if dataset.lower() == \"counties\":\n",
    "    # The name of the script's single output feature class\n",
    "    output_fc = \"multi_year_census_counties\"\n",
    "\n",
    "    # The name of the input feature class from US Census Zips\n",
    "    input_fc = \"County\"\n",
    "\n",
    "    # Names of the folders in which the US Census Bureau's\n",
    "    # zipped and unzipped files reside (files are unzipped programmatically)\n",
    "    zip_dir_name = r\"Zipped_Counties\"\n",
    "    unzip_dir_name = r\"Unzipped_Counties\"\n",
    "\n",
    "elif dataset.lower() == \"tribal\":\n",
    "    # The name of the script's single output feature class\n",
    "    output_fc = \"multi_year_native_american_areas\"\n",
    "\n",
    "    # The name of the input feature class from US Census Zips\n",
    "    input_fc = \"AmericanIndian_AlaskaNative_NativeHawaiianArea\"\n",
    "\n",
    "    # Names of the folders in which the US Census Bureau's\n",
    "    # zipped and unzipped files reside (files are unzipped programmatically)\n",
    "    zip_dir_name = r\"Zipped_Tribal\"\n",
    "    unzip_dir_name = r\"Unzipped_Tribal\"\n",
    "\n",
    "else:\n",
    "    print(\"Please set a valid selector for input dataset!\" \\\n",
    "          \"Qitting script now.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Creation of full paths to output GDB and feature class\n",
    "full_output_gdb = os.path.join(base_dir, output_gdb)\n",
    "full_output_fc = os.path.join(full_output_gdb, output_fc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59204225",
   "metadata": {},
   "source": [
    "### Extract All Zips\n",
    "This function looks at the folder containing the freshly-downloaded ZIP files Census Bureau and unzips the contents of all (a single GDB for each) to the specified output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dccd2fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_zips():\n",
    "\n",
    "    # Create the full path to the folder containing all the zips\n",
    "    for file in os.listdir(os.path.join(base_dir, zip_dir_name)):\n",
    "\n",
    "        # Over-cautious bit to ignore any non-zip files\n",
    "        # that should theoretically not be in this folder\n",
    "        if not file.endswith(\".zip\"):\n",
    "            continue\n",
    "        \n",
    "        # Do the actual unzipping\n",
    "        with ZipFile(os.path.join(base_dir, zip_dir_name, file), 'r') as zip_obj:\n",
    "            zip_obj.extractall(os.path.join(base_dir, unzip_dir_name))\n",
    "\n",
    "# This function generally wouldn't need to be called more than once,\n",
    "# even during development/troubleshooting, so leaving it commented out\n",
    "# in case of an errant click on \"run all cells above\" etc.\n",
    "# UNCOMMENT THE LINE BELOW TO ACTUALLY CALL THIS FUNCTION AND EXTRACT ZIPS\n",
    "#extract_all_zips()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4553f3c",
   "metadata": {},
   "source": [
    "### Get Counties\n",
    "\n",
    "This function checks to make sure each unzipped GDB actually contains a feature class called \"County\". (Ideally safe to assume, but I've worked in fedland too long to make assumptions about tidy data) It rounds up the full paths of all the feature classes it finds into a list \"found_fcs\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89be091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay! Found a AmericanIndian_AlaskaNative_NativeHawaiianArea FC in all gdbs!\n"
     ]
    }
   ],
   "source": [
    "#Initialize empty list to hold full county FC paths\n",
    "found_fcs = []\n",
    "\n",
    "def get_counties():\n",
    "\n",
    "    # Keeping track of whether any GDBs don't have a \"County\" FC\n",
    "    unfound = 0\n",
    "    unfound_gdbs = []\n",
    "\n",
    "    # Loop through the GDBs\n",
    "    for file in os.listdir(os.path.join(base_dir, unzip_dir_name)):\n",
    "\n",
    "        # Ignore any non-GDBs that happen to have gotten into this dir\n",
    "        if not file.endswith(\".gdb\"):\n",
    "            continue\n",
    "\n",
    "        # For each GDB, create full path and set arcpy env\n",
    "        gdb = os.path.join(base_dir, unzip_dir_name, file)\n",
    "        arcpy.env.workspace = gdb\n",
    "        \n",
    "        # Check for \"County\" FC; if found, plop it in my list\n",
    "        if not input_fc in arcpy.ListFeatureClasses():\n",
    "            unfound +=1\n",
    "            unfound_gdbs.append(gdb)\n",
    "        else:\n",
    "            found_fcs.append(os.path.join(base_dir, unzip_dir_name, file, input_fc))\n",
    "\n",
    "    # Reporting on any missing \"County\" FCs\n",
    "    if unfound:\n",
    "        print(f\"Heads up! Didn't find a {input_fc} FC in these GDBs: {unfound_gdbs}\")\n",
    "    else:\n",
    "        print(f\"Yay! Found a {input_fc} FC in all gdbs!\")\n",
    "\n",
    "    return found_fcs\n",
    "\n",
    "found_fcs = get_counties()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e039e1",
   "metadata": {},
   "source": [
    "### Create Year: Full Path Dictionary\n",
    "\n",
    "I'm interested not only in how many variations of a given county boundary exist, but in which came from what year. Obviously, because a single US county feature class from Census Bureau represents a single year, that data is not in the fc attribute table itself. I need to add the year as a field to my final multi-year output county feature class. In order to add it, I must first track it. I do so by converting my Python list of full path strings (which technically contain the year) to a Python dictionary in which the year is key and the full path is the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33cf4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dict that will hold year:fullpath key:value pairs\n",
    "year_fcs_dict = {}\n",
    "\n",
    "def create_dict(year_fcs_dict):\n",
    "\n",
    "    # Resetting intermediate and final lists/dicts\n",
    "    # While testing/developing\n",
    "    pre_dict = {}\n",
    "    pre_list = []\n",
    "    year_fcs_dict.clear()\n",
    "\n",
    "    # Loop through my list of feature class full paths\n",
    "    for fc in found_fcs:\n",
    "\n",
    "        # Isolate the year by splitting the full path string\n",
    "        year = fc.split(\"tlgdb_\")[1].split(\"_a_\")[0]\n",
    "\n",
    "        # Chuck the year in the dict and assign the full path as its value\n",
    "        pre_dict[year] = fc\n",
    "\n",
    "    # I think it's tidier and more logical to process the output dictionary\n",
    "    # in reverse chronological order. That way, if a given county FIPS \n",
    "    # and associated geometry exist across multiple years (i.e. the geometry has not changed),\n",
    "    # the year associated with that row in my final output feature class\n",
    "    # should reflect the most recent year in which that FIPS/geometry pair is found.\n",
    "    # To ensure this is what happens, I reverse-sort my dict here.\n",
    "    pre_list = sorted(pre_dict.items(), reverse=True)\n",
    "    year_fcs_dict = dict(pre_list)\n",
    "\n",
    "    return year_fcs_dict\n",
    "\n",
    "year_fcs_dict = create_dict(year_fcs_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31244057",
   "metadata": {},
   "source": [
    "### Create Output Geodatabase and Feature Class\n",
    "\n",
    "Pretty self-explanatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a5dafb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay! Output GDB already exists.\n",
      "Yay! Output feature class already exists.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Misti\\\\OneDrive\\\\PROJECTS\\\\2025_08_Multi-Year_Census_Counties\\\\2025_08_Multi-Year_Census_Counties.gdb\\\\multi_year_native_american_areas'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_output():\n",
    "\n",
    "    # I was initially just doing year_fcs_dict[0] here,\n",
    "    # but when my insert cursor failed, I realized that a field was added\n",
    "    # to the annual FC sometime between my first and last GDBs.\n",
    "    # I figure it's more likely that Census Bureau will add fields \n",
    "    # in the future rather than remove them, so I'm using as my template\n",
    "    # feature class the NEWEST feature class in my dict.\n",
    "    template_fc = year_fcs_dict[max(year_fcs_dict.keys())]\n",
    "\n",
    "    # Get the spatial reference for my template\n",
    "    spatial_ref = arcpy.Describe(template_fc).spatialReference\n",
    "\n",
    "    # Check whether my output GDB already exists; if not, make it\n",
    "    if not arcpy.Exists(full_output_gdb):\n",
    "        print(\"Creating output GDB...\")\n",
    "        arcpy.management.CreateFileGDB(base_dir, output_gdb)\n",
    "    else:\n",
    "        print(\"Yay! Output GDB already exists.\")\n",
    "\n",
    "    # Check whether my output feature class already exists; if not, make it\n",
    "    if not arcpy.Exists(full_output_fc):\n",
    "        print(\"Creating output feature class...\")\n",
    "        arcpy.management.CreateFeatureclass(full_output_gdb, output_fc, \"POLYGON\", template=template_fc, spatial_reference=spatial_ref)\n",
    "    else:\n",
    "        print(\"Yay! Output feature class already exists.\")\n",
    "\n",
    "    return full_output_fc\n",
    "\n",
    "create_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b3006",
   "metadata": {},
   "source": [
    "### Add Year Field\n",
    "\n",
    "As mentioned above, I want to track in the output feature class which row came from which year. To do so, I am adding a \"Census_Year\" field to the output feature class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3d7a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 'Census_Year' alread exists! Moving on...\n"
     ]
    }
   ],
   "source": [
    "def add_year_field():\n",
    "    \n",
    "    # I wouldn't technically have to do this bit because\n",
    "    # if the field already exists, arcpy will just do nothing and move on...\n",
    "    #...but hey, more messaging is better than less...?\n",
    "    if not \"Census_Year\" in (f.name for f in arcpy.ListFields(full_output_fc)):\n",
    "        print(\"Adding 'Census_Year' field\")\n",
    "        arcpy.management.AddField(full_output_fc, \"Census_Year\", \"SHORT\", field_length=4, field_alias=\"Census Year\")\n",
    "\n",
    "    else:\n",
    "        print(\"Field 'Census_Year' alread exists! Moving on...\")\n",
    "\n",
    "add_year_field()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccc8ed8",
   "metadata": {},
   "source": [
    "### Insert Counties\n",
    "\n",
    "Here is the meat-and-potatoes function that actually iterates all input feature classes and writes the appropriate rows to the output feature class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5886d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_counties(year_fcs_dict):\n",
    "\n",
    "    # Iterate through my dictionary of year:full fc path pairs\n",
    "    for year, fc in year_fcs_dict.items():\n",
    "\n",
    "        # A list of lists may have been more...structurally logical here,\n",
    "        # but let's face it, a one-liner dictionary cursor comprehension is just sexy.\n",
    "        # I only needed the pair of GEOID and SHAPE@LENGTH values for each input row,\n",
    "        # to compare year-over year. Dictionary technically works.\n",
    "        gid_shape_dict = {row[0]: row[1] for row in arcpy.da.SearchCursor(full_output_fc, [\"GEOID\", \"SHAPE@LENGTH\"])}\n",
    "\n",
    "        # Generate the list of fields from the input feature class (remember\n",
    "        # it's from the most recent year) for use with the input fc search cursor.\n",
    "        fields = [f.name for f in arcpy.ListFields(fc)]\n",
    "\n",
    "        # Add the SHAPE@ token because I won't get very far\n",
    "        # writing new geometries without it, and add SHAPE@LENGTH\n",
    "        # for a more efficient geometry comparison year-over-year.\n",
    "        fields.append(\"SHAPE@\")\n",
    "        fields.append(\"SHAPE@LENGTH\")\n",
    "\n",
    "        # Make a copy of fields for use with the insert cursor.\n",
    "        # \"Census_Year\" field only exists in the output fc, not the inputs,\n",
    "        # So to make both cursors happy there must be two field lists.\n",
    "        # Also creating the insert cursor field list from the search cursor\n",
    "        # field list ensures consistent field ordering.\n",
    "        ifields = fields.copy()\n",
    "        ifields.append(\"Census_Year\")\n",
    "\n",
    "        # Fire up the search cursor to iterate through the current input fc\n",
    "        with arcpy.da.SearchCursor(fc, fields) as scursor:\n",
    "            for row in scursor:\n",
    "\n",
    "                # Cut down on verbose duplicated syntax in the logic below\n",
    "                gid = row[fields.index(\"GEOID\")]\n",
    "                shape = row[fields.index(\"SHAPE@LENGTH\")]\n",
    "                \n",
    "                # Now for the (ok really not so) fancy footwork:\n",
    "                # IF the GEOID (i.e. FIPS code) is already in the output feature class...\n",
    "                if gid in gid_shape_dict:\n",
    "\n",
    "                    # If comparing both geoid AND geometry...\n",
    "                    if compare == \"both\":\n",
    "\n",
    "                        # ...we really only want to write this FIPS dup if the geometries differ significantly.\n",
    "                        if abs(shape - gid_shape_dict[gid]) < degrees:\n",
    "\n",
    "                            # If the GEOID is already in the output AND the geometry difference\n",
    "                            # is BELOW the threshold set in the above line, do not pass go,\n",
    "                            # do not collect $200, move on to the next row without writing anything.\n",
    "                            continue\n",
    "\n",
    "                    # Otherwise if we are only comparing geoid, we can just skip straight to the next row\n",
    "                    # Nothin' to see here, folks\n",
    "                    elif compare == \"geoid\":\n",
    "                        continue\n",
    "\n",
    "                # Otherwise, fire up the insert cursor...\n",
    "                with arcpy.da.InsertCursor(full_output_fc, ifields) as icursor:\n",
    "                    \n",
    "                    # ...don't forget to tack the source year onto the end of the row...\n",
    "                    new_row = row + (year,)\n",
    "\n",
    "                    # And actually do the thing\n",
    "                    icursor.insertRow(new_row)\n",
    "\n",
    "insert_counties(year_fcs_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ea352",
   "metadata": {},
   "source": [
    "### Screenshot of output feature class\n",
    "![CONUS US output feature class](https://raw.githubusercontent.com/AlderMaps/arcgis-arcpy/refs/heads/main/multi-year_census_counties.png \"Output Feature Class (with geometry difference at .0001 degrees)\")75% transparency applied to polygons; brighter counties == more (slightly incongruent) geometries written for a given GEOID.<br>\n",
    "I.e. brighter counties/areas have had more geometry changes over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aca71f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR USE WHILE BUILDING SCRIPT AND TROUBLESHOOTING ONLY!!!\n",
    "\n",
    "def truncate_table():\n",
    "    \n",
    "    # Clear out all rows in the output feature class (for dev/testing)\n",
    "    arcpy.management.TruncateTable(full_output_fc)\n",
    "\n",
    "truncate_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc98bc",
   "metadata": {},
   "source": [
    "\n",
    "### Update Aug 12, 2025\n",
    "\n",
    "Put the finishing touches on this and one hour later realize that US Census *actually has* [rest services](https://tigerweb.geo.census.gov/arcgis/rest/services). ðŸ¤¯\n",
    "\n",
    "Slightly mortified that I didn't realize this before today ðŸ˜³; however the 1999 vibe [their page](https://tigerweb.geo.census.gov/tigerwebmain/TIGERweb_restmapservice.html) gives off makes me suspect I'm not the only one who didn't know, and that the page doesn't get a lot of traffic (or love). Ah well, still good to have a script in my portfolio demonstrating working with zip files. ðŸ˜…\n",
    "\n",
    "To-do: Re-do this script leveraging services. ðŸ¤£"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
